# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B53tj4qONPnhycHix1d1APe6hNRzolYr
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X = wine.drop(columns=['quality'])
y = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
from sklearn.random_projection import GaussianRandomProjection

# Apply Randomized Projections
rp = GaussianRandomProjection(n_components=10, random_state=42)
X_train_rp = rp.fit_transform(X_train)
X_test_rp = rp.transform(X_test)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import time
import matplotlib.pyplot as plt

# Define the Neural Network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_rp.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

# Train the model and capture computation time
start_time = time.time()
history = model.fit(X_train_rp, y_train, epochs=100, batch_size=32, validation_data=(X_test_rp, y_test), verbose=1)
end_time = time.time()
print(f"Computation time for training the Neural Network with Randomized Projections: {end_time - start_time:.4f} seconds")

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss- RP-NN')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.grid(True)
plt.show()

import numpy as np
from sklearn.metrics import accuracy_score

# Convert regression output to classification (for the sake of plotting accuracy)
def convert_to_classification(y, threshold=5.5):
    return (y >= threshold).astype(int)

train_sizes = np.linspace(0.1, 0.9, 9)  # Avoiding 1.0 to prevent the error
train_accuracies = []
test_accuracies = []

for train_size in train_sizes:
    X_train_part, _, y_train_part, _ = train_test_split(X_train_rp, y_train, train_size=train_size, random_state=42)

    model.fit(X_train_part, y_train_part, epochs=100, batch_size=32, verbose=0)
    y_train_pred = convert_to_classification(model.predict(X_train_part))
    y_test_pred = convert_to_classification(model.predict(X_test_rp))

    train_accuracies.append(accuracy_score(convert_to_classification(y_train_part), y_train_pred))
    test_accuracies.append(accuracy_score(convert_to_classification(y_test), y_test_pred))

# Plot training size vs. accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_sizes, train_accuracies, marker='o', label='Train')
plt.plot(train_sizes, test_accuracies, marker='o', label='Test')
plt.title('Training Size vs. Accuracy - RP-NN')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X = wine.drop(columns=['quality'])
y = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Apply PCA
pca = PCA(n_components=10, random_state=42)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Define the Neural Network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_pca.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

# Train the model and capture computation time
start_time = time.time()
history = model.fit(X_train_pca, y_train, epochs=100, batch_size=32, validation_data=(X_test_pca, y_test), verbose=1)
end_time = time.time()
print(f"Computation time for training the Neural Network with PCA: {end_time - start_time:.4f} seconds")

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss - PCA-NN')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.grid(True)
plt.show()

# Convert regression output to classification (for the sake of plotting accuracy)
def convert_to_classification(y, threshold=5.5):
    return (y >= threshold).astype(int)

train_sizes = np.linspace(0.1, 0.9, 9)  # Avoiding 1.0 to prevent the error
train_accuracies = []
test_accuracies = []

for train_size in train_sizes:
    X_train_part, _, y_train_part, _ = train_test_split(X_train_pca, y_train, train_size=train_size, random_state=42)

    model.fit(X_train_part, y_train_part, epochs=100, batch_size=32, verbose=0)
    y_train_pred = convert_to_classification(model.predict(X_train_part))
    y_test_pred = convert_to_classification(model.predict(X_test_pca))

    train_accuracies.append(accuracy_score(convert_to_classification(y_train_part), y_train_pred))
    test_accuracies.append(accuracy_score(convert_to_classification(y_test), y_test_pred))

# Plot training size vs. accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_sizes, train_accuracies, marker='o', label='Train')
plt.plot(train_sizes, test_accuracies, marker='o', label='Test')
plt.title('Training Size vs. Accuracy - PCA-NN')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import FastICA
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X = wine.drop(columns=['quality'])
y = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Apply ICA
ica = FastICA(n_components=10, random_state=42)
X_train_ica = ica.fit_transform(X_train)
X_test_ica = ica.transform(X_test)

# Define the Neural Network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_ica.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

# Train the model and capture computation time
start_time = time.time()
history = model.fit(X_train_ica, y_train, epochs=100, batch_size=32, validation_data=(X_test_ica, y_test), verbose=1)
end_time = time.time()
print(f"Computation time for training the Neural Network with ICA: {end_time - start_time:.4f} seconds")

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss - ICA-NN')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.grid(True)
plt.show()

# Convert regression output to classification (for the sake of plotting accuracy)
def convert_to_classification(y, threshold=5.5):
    return (y >= threshold).astype(int)

train_sizes = np.linspace(0.1, 0.9, 9)  # Avoiding 1.0 to prevent the error
train_accuracies = []
test_accuracies = []

for train_size in train_sizes:
    X_train_part, _, y_train_part, _ = train_test_split(X_train_ica, y_train, train_size=train_size, random_state=42)

    model.fit(X_train_part, y_train_part, epochs=100, batch_size=32, verbose=0)
    y_train_pred = convert_to_classification(model.predict(X_train_part))
    y_test_pred = convert_to_classification(model.predict(X_test_ica))

    train_accuracies.append(accuracy_score(convert_to_classification(y_train_part), y_train_pred))
    test_accuracies.append(accuracy_score(convert_to_classification(y_test), y_test_pred))

# Plot training size vs. accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_sizes, train_accuracies, marker='o', label='Train')
plt.plot(train_sizes, test_accuracies, marker='o', label='Test')
plt.title('Training Size vs. Accuracy - ICA-NN')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import FastICA
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import time
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X = wine.drop(columns=['quality'])
y = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Apply ICA
ica = FastICA(n_components=10, random_state=42)
X_train_ica = ica.fit_transform(X_train)
X_test_ica = ica.transform(X_test)

# Define the Neural Network model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train_ica.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])

# Train the model and capture computation time
start_time = time.time()
history = model.fit(X_train_ica, y_train, epochs=100, batch_size=32, validation_data=(X_test_ica, y_test), verbose=1)
end_time = time.time()
print(f"Computation time for training the Neural Network with ICA: {end_time - start_time:.4f} seconds")

# Plot training & validation loss values
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss - ICA-NN')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.grid(True)
plt.show()

# Convert regression output to classification (for the sake of plotting accuracy)
def convert_to_classification(y, threshold=5.5):
    return (y >= threshold).astype(int)

train_sizes = np.linspace(0.1, 0.9, 9)  # Avoiding 1.0 to prevent the error
train_accuracies = []
test_accuracies = []

for train_size in train_sizes:
    X_train_part, _, y_train_part, _ = train_test_split(X_train_ica, y_train, train_size=train_size, random_state=42)

    model.fit(X_train_part, y_train_part, epochs=100, batch_size=32, verbose=0)
    y_train_pred = convert_to_classification(model.predict(X_train_part))
    y_test_pred = convert_to_classification(model.predict(X_test_ica))

    train_accuracies.append(accuracy_score(convert_to_classification(y_train_part), y_train_pred))
    test_accuracies.append(accuracy_score(convert_to_classification(y_test), y_test_pred))

# Plot training size vs. accuracy
plt.figure(figsize=(10, 5))
plt.plot(train_sizes, train_accuracies, marker='o', label='Train')
plt.plot(train_sizes, test_accuracies, marker='o', label='Test')
plt.title('Training Size vs. Accuracy - ICA-NN')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()