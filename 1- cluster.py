# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K1LFVItq6muTz2Dr9Dl5qij4feTmxtRW
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score
from sklearn.random_projection import GaussianRandomProjection
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_wine_scaled = scaler.fit_transform(X_wine)

# Split the dataset into training and testing sets
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

# Define the range for the number of components
range_n_components = range(2, 11)

# Compute BIC and Silhouette Scores for different number of components
bic = []
silhouette_scores = []

for n_components in range_n_components:
    gmm = GaussianMixture(n_components=n_components, random_state=42)
    gmm.fit(X_wine_train)
    cluster_labels = gmm.predict(X_wine_train)
    bic.append(gmm.bic(X_wine_train))
    silhouette_avg = silhouette_score(X_wine_train, cluster_labels)
    silhouette_scores.append(silhouette_avg)

# Plot the BIC results
plt.figure(figsize=(10, 5))
plt.plot(range_n_components, bic, marker='o')
plt.title('BIC for Optimal Number of Components (EM) - Wine Dataset')
plt.xlabel('Number of components')
plt.ylabel('BIC')
plt.grid(True)
plt.show()

# Plot the Silhouette Score results
plt.figure(figsize=(10, 5))
plt.plot(range_n_components, silhouette_scores, marker='o')
plt.title('Silhouette Score for Optimal Number of Components (EM) - Wine Dataset')
plt.xlabel('Number of components')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_wine_scaled = scaler.fit_transform(X_wine)

# Split the dataset into training and testing sets
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_wine_scaled = scaler.fit_transform(X_wine)

# Split the dataset into training and testing sets
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

# Optimal number of clusters for EM
optimal_n_clusters_em = 6

# Apply Expectation Maximization
gmm = GaussianMixture(n_components=optimal_n_clusters_em, random_state=42)
wine_train_clusters = gmm.fit_predict(X_wine_train)
wine_test_clusters = gmm.predict(X_wine_test)

# 2D plot using the first two features
plt.figure(figsize=(10, 6))
plt.scatter(X_wine_train[:, 0], X_wine_train[:, 1], c=wine_train_clusters, cmap='viridis', s=50, alpha=0.6)
plt.colorbar(label='Cluster Label')
plt.title('EM Clustering (2D) - Wine Dataset')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True)
plt.show()

# 3D plot using the first three features
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_wine_train[:, 0], X_wine_train[:, 1], X_wine_train[:, 2], c=wine_train_clusters, cmap='viridis', s=50, alpha=0.6)
legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
ax.add_artist(legend1)
ax.set_title('EM Clustering (3D) - Wine Dataset')
ax.set_xlabel('Feature 1')
ax.set_ylabel('Feature 2')
ax.set_zlabel('Feature 3')
plt.colorbar(scatter, ax=ax, pad=0.1)
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Load the breast cancer dataset
breast_cancer_path = '/content/breast/breast-cancer.data'
column_names = ['Class', 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat']
breast_data = pd.read_csv(breast_cancer_path, names=column_names)

# Encode categorical variables
label_encoders = {}
for column in breast_data.select_dtypes(include=['object']).columns:
    label_encoders[column] = LabelEncoder()
    breast_data[column] = label_encoders[column].fit_transform(breast_data[column])

# Separate features and labels
X_breast = breast_data.drop(columns=['Class'])
y_breast = breast_data['Class']

# Normalize the features
scaler = StandardScaler()
X_breast_scaled = scaler.fit_transform(X_breast)

# Split the dataset into training and testing sets
X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast_scaled, y_breast, test_size=0.2, random_state=42)

# Define the range for the number of components
range_n_components = range(2, 11)

# Compute BIC and Silhouette Scores for different number of components
bic = []
silhouette_scores = []

for n_components in range_n_components:
    gmm = GaussianMixture(n_components=n_components, random_state=42)
    gmm.fit(X_breast_train)
    cluster_labels = gmm.predict(X_breast_train)
    bic.append(gmm.bic(X_breast_train))
    silhouette_avg = silhouette_score(X_breast_train, cluster_labels)
    silhouette_scores.append(silhouette_avg)

# Plot the BIC results
plt.figure(figsize=(10, 5))
plt.plot(range_n_components, bic, marker='o')
plt.title('BIC for Optimal Number of Components (EM) - Breast Cancer Dataset')
plt.xlabel('Number of components')
plt.ylabel('BIC')
plt.grid(True)
plt.show()

# Plot the Silhouette Score results
plt.figure(figsize=(10, 5))
plt.plot(range_n_components, silhouette_scores, marker='o')
plt.title('Silhouette Score for Optimal Number of Components (EM) - Breast Cancer Dataset')
plt.xlabel('Number of components')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load the breast cancer dataset
column_names = ["Class", "age", "menopause", "tumor-size", "inv-nodes", "node-caps", "deg-malig", "breast", "breast-quad", "irradiat"]
breast_cancer = pd.read_csv('/content/breast/breast-cancer.data', header=None, names=column_names)

# Preprocessing: Convert categorical variables to numerical
for column in breast_cancer.columns:
    breast_cancer[column] = breast_cancer[column].astype('category').cat.codes

# Separate features and labels
X_breast = breast_cancer.drop(columns=['Class'])
y_breast = breast_cancer['Class']

# Normalize the features
scaler = StandardScaler()
X_breast_scaled = scaler.fit_transform(X_breast)

# Split the dataset into training and testing sets
X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast_scaled, y_breast, test_size=0.2, random_state=42)

# Optimal number of clusters for EM
optimal_n_clusters_em_breast = 9

# Apply Expectation Maximization
gmm_breast = GaussianMixture(n_components=optimal_n_clusters_em_breast, random_state=42)
breast_train_clusters = gmm_breast.fit_predict(X_breast_train)
breast_test_clusters = gmm_breast.predict(X_breast_test)

# 2D plot using the first two features
plt.figure(figsize=(10, 6))
plt.scatter(X_breast_train[:, 0], X_breast_train[:, 1], c=breast_train_clusters, cmap='viridis', s=50, alpha=0.6)
plt.colorbar(label='Cluster Label')
plt.title('EM Clustering (2D) - Breast Cancer Dataset')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True)
plt.show()

# 3D plot using the first three features
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_breast_train[:, 0], X_breast_train[:, 1], X_breast_train[:, 2], c=breast_train_clusters, cmap='viridis', s=50, alpha=0.6)
legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
ax.add_artist(legend1)
ax.set_title('EM Clustering (3D) - Breast Cancer Dataset')
ax.set_xlabel('Feature 1')
ax.set_ylabel('Feature 2')
ax.set_zlabel('Feature 3')
plt.colorbar(scatter, ax=ax, pad=0.1)
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_wine_scaled = scaler.fit_transform(X_wine)

# Split the dataset into training and testing sets
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

# Define the range for the number of clusters
range_n_clusters = range(2, 11)

# Compute WCSS (Within-Cluster Sum of Squares) for the Elbow Method
wcss = []
silhouette_scores = []

for n_clusters in range_n_clusters:
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(X_wine_train)
    wcss.append(kmeans.inertia_)
    silhouette_avg = silhouette_score(X_wine_train, cluster_labels)
    silhouette_scores.append(silhouette_avg)

# Plot the Elbow Method results
plt.figure(figsize=(10, 5))
plt.plot(range_n_clusters, wcss, marker='o')
plt.title('Elbow Method for Optimal Number of Clusters (K-Means) - Wine Dataset')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.grid(True)
plt.show()

# Plot the Silhouette Score results
plt.figure(figsize=(10, 5))
plt.plot(range_n_clusters, silhouette_scores, marker='o')
plt.title('Silhouette Score for Optimal Number of Clusters (K-Means) - Wine Dataset')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()


import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')

# Combine the two datasets
wine = pd.concat([wine_red, wine_white], ignore_index=True)

# Separate features and labels
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']

# Normalize the features
scaler = StandardScaler()
X_wine_scaled = scaler.fit_transform(X_wine)

# Split the dataset into training and testing sets
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

# Optimal number of clusters for K-Means
optimal_n_clusters_kmeans = 4

# Apply K-Means
kmeans = KMeans(n_clusters=optimal_n_clusters_kmeans, random_state=42)
wine_train_clusters = kmeans.fit_predict(X_wine_train)
wine_test_clusters = kmeans.predict(X_wine_test)

# 2D plot using the first two features
plt.figure(figsize=(10, 6))
plt.scatter(X_wine_train[:, 0], X_wine_train[:, 1], c=wine_train_clusters, cmap='viridis', s=50, alpha=0.6)
plt.colorbar(label='Cluster Label')
plt.title('K-Means Clustering (2D) - Wine Dataset')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True)
plt.show()

# 3D plot using the first three features
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_wine_train[:, 0], X_wine_train[:, 1], X_wine_train[:, 2], c=wine_train_clusters, cmap='viridis', s=50, alpha=0.6)
legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
ax.add_artist(legend1)
ax.set_title('K-Means Clustering (3D) - Wine Dataset')
ax.set_xlabel('Feature 1')
ax.set_ylabel('Feature 2')
ax.set_zlabel('Feature 3')
plt.colorbar(scatter, ax=ax, pad=0.1)
plt.show()

import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Load the breast cancer dataset
breast_cancer_path = '/content/breast/breast-cancer.data'
column_names = ['Class', 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat']
breast_data = pd.read_csv(breast_cancer_path, names=column_names)

# Encode categorical variables
label_encoders = {}
for column in breast_data.select_dtypes(include=['object']).columns:
    label_encoders[column] = LabelEncoder()
    breast_data[column] = label_encoders[column].fit_transform(breast_data[column])

# Separate features and labels
X_breast = breast_data.drop(columns=['Class'])
y_breast = breast_data['Class']

# Normalize the features
scaler = StandardScaler()
X_breast_scaled = scaler.fit_transform(X_breast)

# Split the dataset into training and testing sets
X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast_scaled, y_breast, test_size=0.2, random_state=42)

# Define the range for the number of clusters
range_n_clusters = range(2, 11)

# Compute WCSS (Within-Cluster Sum of Squares) for the Elbow Method
wcss = []
silhouette_scores = []

for n_clusters in range_n_clusters:
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    cluster_labels = kmeans.fit_predict(X_breast_train)
    wcss.append(kmeans.inertia_)
    silhouette_avg = silhouette_score(X_breast_train, cluster_labels)
    silhouette_scores.append(silhouette_avg)

# Plot the Elbow Method results
plt.figure(figsize=(10, 5))
plt.plot(range_n_clusters, wcss, marker='o')
plt.title('Elbow Method for Optimal Number of Clusters (K-Means) - Breast Cancer Dataset')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.grid(True)
plt.show()

# Plot the Silhouette Score results
plt.figure(figsize=(10, 5))
plt.plot(range_n_clusters, silhouette_scores, marker='o')
plt.title('Silhouette Score for Optimal Number of Clusters (K-Means) - Breast Cancer Dataset')
plt.xlabel('Number of clusters')
plt.ylabel('Silhouette Score')
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Load the breast cancer dataset
column_names = ["Class", "age", "menopause", "tumor-size", "inv-nodes", "node-caps", "deg-malig", "breast", "breast-quad", "irradiat"]
breast_cancer = pd.read_csv('/content/breast/breast-cancer.data', header=None, names=column_names)

# Preprocessing: Convert categorical variables to numerical
for column in breast_cancer.columns:
    breast_cancer[column] = breast_cancer[column].astype('category').cat.codes

# Separate features and labels
X_breast = breast_cancer.drop(columns=['Class'])
y_breast = breast_cancer['Class']

# Normalize the features
scaler = StandardScaler()
X_breast_scaled = scaler.fit_transform(X_breast)

# Split the dataset into training and testing sets
X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast_scaled, y_breast, test_size=0.2, random_state=42)

# Optimal number of clusters for K-Means
optimal_n_clusters_kmeans_breast = 4

# Apply K-Means
kmeans_breast = KMeans(n_clusters=optimal_n_clusters_kmeans_breast, random_state=42)
breast_train_clusters = kmeans_breast.fit_predict(X_breast_train)
breast_test_clusters = kmeans_breast.predict(X_breast_test)

# 2D plot using the first two features
plt.figure(figsize=(10, 6))
plt.scatter(X_breast_train[:, 0], X_breast_train[:, 1], c=breast_train_clusters, cmap='viridis', s=50, alpha=0.6)
plt.colorbar(label='Cluster Label')
plt.title('K-Means Clustering (2D) - Breast Cancer Dataset')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.grid(True)
plt.show()

# 3D plot using the first three features
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
scatter = ax.scatter(X_breast_train[:, 0], X_breast_train[:, 1], X_breast_train[:, 2], c=breast_train_clusters, cmap='viridis', s=50, alpha=0.6)
legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
ax.add_artist(legend1)
ax.set_title('K-Means Clustering (3D) - Breast Cancer Dataset')
ax.set_xlabel('Feature 1')
ax.set_ylabel('Feature 2')
ax.set_zlabel('Feature 3')
plt.colorbar(scatter, ax=ax, pad=0.1)
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')
wine = pd.concat([wine_red, wine_white], ignore_index=True)
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']
scaler_wine = StandardScaler()
X_wine_scaled = scaler_wine.fit_transform(X_wine)
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

# Load the breast cancer dataset
column_names = ["Class", "age", "menopause", "tumor-size", "inv-nodes", "node-caps", "deg-malig", "breast", "breast-quad", "irradiat"]
breast_cancer = pd.read_csv('/content/breast/breast-cancer.data', header=None, names=column_names)
for column in breast_cancer.columns:
    breast_cancer[column] = breast_cancer[column].astype('category').cat.codes
X_breast = breast_cancer.drop(columns=['Class'])
y_breast = breast_cancer['Class']
scaler_breast = StandardScaler()
X_breast_scaled = scaler_breast.fit_transform(X_breast)
X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast_scaled, y_breast, test_size=0.2, random_state=42)

# Determine BIC for different number of clusters
n_components = np.arange(2, 11)
bics_wine = []
bics_breast = []

for n in n_components:
    gmm_wine = GaussianMixture(n_components=n, random_state=42)
    gmm_wine.fit(X_wine_train)
    bics_wine.append(gmm_wine.bic(X_wine_train))

    gmm_breast = GaussianMixture(n_components=n, random_state=42)
    gmm_breast.fit(X_breast_train)
    bics_breast.append(gmm_breast.bic(X_breast_train))

# Create a combined plot
plt.figure(figsize=(14, 6))

# Plot BIC for Wine dataset
plt.subplot(1, 2, 1)
plt.plot(n_components, bics_wine, marker='o')
plt.title('BIC for Optimal Number of Components (EM) - Wine Dataset')
plt.xlabel('Number of components')
plt.ylabel('BIC')
plt.grid(True)

# Plot BIC for Breast Cancer dataset
plt.subplot(1, 2, 2)
plt.plot(n_components, bics_breast, marker='o')
plt.title('BIC for Optimal Number of Components (EM) - Breast Cancer Dataset')
plt.xlabel('Number of components')
plt.ylabel('BIC')
plt.grid(True)

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load the wine dataset
wine_red = pd.read_csv('/content/wine/winequality-red.csv', sep=';')
wine_white = pd.read_csv('/content/wine/winequality-white.csv', sep=';')
wine = pd.concat([wine_red, wine_white], ignore_index=True)
X_wine = wine.drop(columns=['quality'])
y_wine = wine['quality']
scaler_wine = StandardScaler()
X_wine_scaled = scaler_wine.fit_transform(X_wine)
X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(X_wine_scaled, y_wine, test_size=0.2, random_state=42)

# Load the breast cancer dataset
column_names = ["Class", "age", "menopause", "tumor-size", "inv-nodes", "node-caps", "deg-malig", "breast", "breast-quad", "irradiat"]
breast_cancer = pd.read_csv('/content/breast/breast-cancer.data', header=None, names=column_names)
for column in breast_cancer.columns:
    breast_cancer[column] = breast_cancer[column].astype('category').cat.codes
X_breast = breast_cancer.drop(columns=['Class'])
y_breast = breast_cancer['Class']
scaler_breast = StandardScaler()
X_breast_scaled = scaler_breast.fit_transform(X_breast)
X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(X_breast_scaled, y_breast, test_size=0.2, random_state=42)

# Determine WCSS for different number of clusters
n_clusters = np.arange(2, 11)
wcss_wine = []
wcss_breast = []

for n in n_clusters:
    kmeans_wine = KMeans(n_clusters=n, random_state=42)
    kmeans_wine.fit(X_wine_train)
    wcss_wine.append(kmeans_wine.inertia_)

    kmeans_breast = KMeans(n_clusters=n, random_state=42)
    kmeans_breast.fit(X_breast_train)
    wcss_breast.append(kmeans_breast.inertia_)

# Create a combined plot
plt.figure(figsize=(14, 6))

# Plot WCSS for Wine dataset
plt.subplot(1, 2, 1)
plt.plot(n_clusters, wcss_wine, marker='o')
plt.title('WCSS for Optimal Number of Clusters (K-Means) - Wine Dataset')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.grid(True)

# Plot WCSS for Breast Cancer dataset
plt.subplot(1, 2, 2)
plt.plot(n_clusters, wcss_breast, marker='o')
plt.title('WCSS for Optimal Number of Clusters (K-Means) - Breast Cancer Dataset')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.grid(True)

plt.tight_layout()
plt.show()